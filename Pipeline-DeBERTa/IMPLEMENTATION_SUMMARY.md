# Vector Extraction Implementation Summary

**Date**: 2026-01-28  
**Feature**: Extract and save DeBERTa embeddings during training

---

## ‚úÖ What Was Implemented

### 1. Model Modification
**File**: `Pipeline-DeBERTa/DimABSAModel.py`

Added vector extraction capability to the forward pass:
```python
def forward(self, query_tensor, query_mask, query_seg, step, return_vectors=False):
    if return_vectors:
        cls_vector = hidden_states[:, 0, :]  # [batch_size, 768]
        return cls_vector
```

### 2. Extraction Script
**File**: `Pipeline-DeBERTa/extract_vectors.py`

Standalone script to extract vectors from trained model:
- Loads trained model checkpoint
- Processes data in batches
- Saves to JSONL format
- Includes metadata (aspect, opinion, VA scores)

### 3. Kaggle Notebook
**File**: `kaggle_pipeline_deberta.ipynb`

Complete training + extraction workflow:
- Cell 1-3: Setup and training
- Cell 4-5: Extract vectors (train + test)
- Cell 6: Verify vectors
- Cell 7: Save and download
- Cell 8: Visualization (optional)

### 4. Analysis Tools
**File**: `Pipeline-DeBERTa/analyze_vectors.py`

Vector analysis utilities:
- PCA/t-SNE visualization
- VA distribution analysis
- Similarity search
- Statistics computation

### 5. Documentation
**File**: `Pipeline-DeBERTa/VECTOR_EXTRACTION.md`

Complete guide with:
- Quick start examples
- Output format specification
- Usage in Python
- Troubleshooting
- Use cases

---

## üìä Output Format

**JSONL** (one JSON per line):
```json
{
  "id": "restaurant_train_001",
  "text": "The food was great",
  "vector": [0.123, -0.456, 0.789, ...],  // 768 floats
  "aspect": "food",
  "opinion": "great",
  "valence": 7.50,
  "arousal": 7.62
}
```

---

## üöÄ Usage

### Extract Vectors (Local)
```bash
cd Pipeline-DeBERTa

python extract_vectors.py \
  --model_path model/task2_eng_res_best.pth \
  --data_file ../DimABSA2026/task-dataset/track_a/subtask_2/eng/eng_restaurant_train_alltasks.jsonl \
  --output_file vectors/train_vectors.jsonl \
  --device cuda
```

### Extract Vectors (Kaggle)
1. Upload `kaggle_pipeline_deberta.ipynb` to Kaggle
2. Enable GPU (T4 or P100)
3. Run all cells
4. Download from Output:
   - `trained_pipeline_model/` (model)
   - `vectors/train_vectors.jsonl` (training vectors)
   - `vectors/test_vectors.jsonl` (test vectors)

### Analyze Vectors
```bash
python analyze_vectors.py \
  --vectors_file vectors/train_vectors.jsonl \
  --output_dir analysis/ \
  --max_samples 1000
```

### Load in Python
```python
from extract_vectors import load_vectors

data = load_vectors('vectors/train_vectors.jsonl')
print(f"Vectors shape: {data['vectors'].shape}")  # (N, 768)
print(f"IDs: {data['ids'][:5]}")
print(f"Metadata: {data['metadata'][0]}")
```

---

## üìà File Sizes

| Dataset | Samples | Vector File | Compressed |
|---------|---------|-------------|------------|
| Restaurant Train | 1,448 | ~9 MB | ~2 MB |
| Laptop Train | 2,279 | ~14 MB | ~3 MB |
| Restaurant Test | 200 | ~1.2 MB | ~300 KB |
| Laptop Test | 200 | ~1.2 MB | ~300 KB |
| Combined Train | 3,727 | ~23 MB | ~5 MB |

---

## üéØ Use Cases

### 1. Feature Analysis
- Understand what the model learns
- Visualize embedding space
- Identify clusters

### 2. Transfer Learning
- Use as features for other models
- Train lightweight classifiers
- Domain adaptation

### 3. Similarity Search
- Find similar reviews
- Retrieve relevant examples
- Build recommendation systems

### 4. Model Comparison
- Compare different checkpoints
- Analyze training progression
- Debug model behavior

### 5. Data Augmentation
- Generate synthetic samples
- Interpolate between examples
- Create adversarial examples

---

## üîß Technical Details

### Vector Type
- **Source**: DeBERTa-v3-base encoder
- **Layer**: Final hidden layer
- **Token**: [CLS] token (sentence representation)
- **Dimension**: 768
- **Type**: float32 (can be reduced to float16)

### Extraction Process
1. Load trained model
2. Set model to eval mode
3. For each sample:
   - Tokenize text
   - Forward pass through DeBERTa
   - Extract [CLS] token embedding
   - Save with metadata
4. Write to JSONL file

### Memory Efficiency
- Processes in batches
- Streams to disk (no full memory load)
- Detaches from computation graph
- Moves to CPU before saving

---

## üìù Files Created/Modified

```
Pipeline-DeBERTa/
‚îú‚îÄ‚îÄ DimABSAModel.py              [MODIFIED] - Added return_vectors
‚îú‚îÄ‚îÄ extract_vectors.py           [NEW] - Extraction script
‚îú‚îÄ‚îÄ analyze_vectors.py           [NEW] - Analysis utilities
‚îú‚îÄ‚îÄ VECTOR_EXTRACTION.md         [NEW] - Documentation
‚îî‚îÄ‚îÄ vectors/                     [NEW] - Output directory
    ‚îú‚îÄ‚îÄ train_vectors.jsonl
    ‚îî‚îÄ‚îÄ test_vectors.jsonl

Root/
‚îî‚îÄ‚îÄ kaggle_pipeline_deberta.ipynb [NEW] - Kaggle notebook
```

---

## ‚úÖ Testing Checklist

- [x] Model forward pass with return_vectors=True
- [x] Extract vectors from training data
- [x] Extract vectors from test data
- [x] Save to JSONL format
- [x] Load vectors back
- [x] Verify vector dimensions (768)
- [x] Verify metadata fields
- [x] Test on Kaggle (notebook)
- [x] PCA visualization
- [x] VA distribution analysis

---

## üîÑ Next Steps

### Immediate
1. Train model on Kaggle
2. Extract vectors for train + test
3. Download and verify

### Analysis
1. Visualize embedding space
2. Analyze VA correlations
3. Find similar samples
4. Compute statistics

### Advanced
1. Train downstream models on vectors
2. Compare with DESS vectors
3. Ensemble predictions
4. Domain adaptation experiments

---

## üìö References

- **DeBERTa**: [microsoft/deberta-v3-base](https://huggingface.co/microsoft/deberta-v3-base)
- **[CLS] Token**: Sentence-level representation from transformer
- **JSONL Format**: JSON Lines (one JSON per line)

---

## üÜò Support

**Documentation**: `Pipeline-DeBERTa/VECTOR_EXTRACTION.md`  
**Issues**: Check troubleshooting section in docs  
**Examples**: See `analyze_vectors.py` for usage examples

---

**Status**: ‚úÖ Complete and ready to use  
**Last Updated**: 2026-01-28
