# Complete Pipeline: Training to Submission

## Visual Flow

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                         TRAINING PHASE                            â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“ eng_restaurant_train_alltasks.jsonl
   {"ID": "1", "Text": "sake list was extensive", 
    "Triplet": [{"Aspect": "sake list", "Opinion": "extensive", "VA": "7.83#8.00"}]}
                              â†“
         [convert_dimabsa_to_dess.py]
         â€¢ Tokenize: ["sake", "list", "was", "extensive"]
         â€¢ Find spans: aspect[0:2], opinion[3:4]
         â€¢ Add POS tags (spaCy)
         â€¢ Add dependencies (spaCy)
                              â†“
ğŸ“ train_dep_triple_polarity_result.json
   {"tokens": ["sake", "list", "was", "extensive"],
    "entities": [{"type": "target", "start": 0, "end": 2}, ...],
    "sentiments": [{"type": "7.83#8.00", "head": 0, "tail": 1}],
    "pos": [...], "dependency": [...]}
                              â†“
              [Modified DESS Model]
              â€¢ DeBERTa encoder
              â€¢ Dual-channel GCN
              â€¢ VA regression head (2 outputs)
              â€¢ Train with MSE loss
                              â†“
ğŸ’¾ best_model.pt (Trained checkpoint)


â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                        INFERENCE PHASE                            â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“ test_eng_restaurant.jsonl (Competition provides)
   {"ID": "test_1", "Text": "sake list was extensive"}
                              â†“
         [convert_dimabsa_to_dess.py]
         â€¢ Same conversion (no labels)
                              â†“
ğŸ“ test_dep_triple_polarity_result.json
   {"tokens": ["sake", "list", "was", "extensive"],
    "entities": [], "sentiments": [],  â† Empty (to be predicted)
    "pos": [...], "dependency": [...]}
                              â†“
              [Trained DESS Model]
              â€¢ Load best_model.pt
              â€¢ Forward pass (evaluate=True)
              â€¢ Predict entities + VA scores
                              â†“
ğŸ”® DESS Predictions (Internal format)
   entities: [{"type": "target", "start": 0, "end": 2, "score": 0.95},
              {"type": "opinion", "start": 3, "end": 4, "score": 0.92}]
   sentiments: [{"head": 0, "tail": 1, "va_scores": [7.85, 7.98]}]
                              â†“
         [inference_and_submit.py]
         â€¢ Extract entities from predictions
         â€¢ Convert token indices â†’ text spans
         â€¢ Format VA scores: "7.85#7.98"
                              â†“
ğŸ“ pred_eng_restaurant.jsonl (Submission file)
   {"ID": "test_1", 
    "Triplet": [{"Aspect": "sake list", "Opinion": "extensive", "VA": "7.85#7.98"}]}
                              â†“
         [validate_submission.py]
         â€¢ Check format
         â€¢ Validate VA range [1.00, 9.00]
         â€¢ Verify all IDs present
                              â†“
âœ… VALID SUBMISSION
                              â†“
         Upload to CodaBench ğŸš€
```

---

## Key Conversion Points

### Point 1: Training Data Conversion
```
DimABSA (Text + Labels) â†’ DESS (Tokens + Indices + Labels)
```
- **Input**: "sake list was extensive" + VA "7.83#8.00"
- **Output**: tokens[0:2] = aspect, tokens[3:4] = opinion, VA stored
- **Purpose**: Train DESS model

### Point 2: Test Data Conversion
```
DimABSA (Text only) â†’ DESS (Tokens + Indices, no labels)
```
- **Input**: "sake list was extensive"
- **Output**: tokens + linguistic features, empty predictions
- **Purpose**: Prepare for inference

### Point 3: Prediction Conversion
```
DESS (Token indices + VA) â†’ DimABSA (Text spans + VA)
```
- **Input**: entities[0] = tokens[0:2], VA = [7.85, 7.98]
- **Output**: "sake list", "extensive", "7.85#7.98"
- **Purpose**: Create submission file

---

## File Structure

```
DimABSANew/
â”œâ”€â”€ DimABSA2026/
â”‚   â””â”€â”€ task-dataset/track_a/subtask_2/eng/
â”‚       â”œâ”€â”€ eng_restaurant_train_alltasks.jsonl    â† Training input
â”‚       â””â”€â”€ eng_restaurant_dev_task2.jsonl         â† Validation input
â”‚
â”œâ”€â”€ DESS/Codebase/
â”‚   â”œâ”€â”€ data/dimabsa_eng_restaurant/
â”‚   â”‚   â”œâ”€â”€ train_dep_triple_polarity_result.json  â† Converted training
â”‚   â”‚   â””â”€â”€ test_dep_triple_polarity_result.json   â† Converted validation
â”‚   â”‚
â”‚   â”œâ”€â”€ savemodels/
â”‚   â”‚   â””â”€â”€ best_model.pt                          â† Trained checkpoint
â”‚   â”‚
â”‚   â””â”€â”€ train.py                                    â† Training script
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ convert_dimabsa_to_dess.py                 â† Forward converter
â”‚   â”œâ”€â”€ inference_and_submit.py                    â† Inference + reverse
â”‚   â””â”€â”€ validate_submission.py                     â† Validation
â”‚
â””â”€â”€ submissions/
    â””â”€â”€ pred_eng_restaurant.jsonl                  â† Final submission
```

---

## Implementation Checklist

### Phase 1: Data Conversion âœ…
- [ ] Implement `convert_dimabsa_to_dess.py`
  - [ ] Tokenization
  - [ ] Span finding
  - [ ] POS tagging (spaCy)
  - [ ] Dependency parsing (spaCy)
  - [ ] JSON output
- [ ] Test on sample data
- [ ] Convert all training datasets

### Phase 2: Model Modification âœ…
- [ ] Modify `D2E2S_Model.py`
  - [ ] Replace sentiment classifier with VA regressor
  - [ ] Update forward pass
- [ ] Modify `loss.py`
  - [ ] Add MSE loss for VA
- [ ] Update `Parameter.py`
  - [ ] Add DimABSA dataset configs

### Phase 3: Training âœ…
- [ ] Train on English restaurant
- [ ] Validate on dev set
- [ ] Monitor RMSE and continuous F1
- [ ] Save best checkpoint

### Phase 4: Inference & Submission âœ…
- [ ] Implement `inference_and_submit.py`
  - [ ] Load trained model
  - [ ] Run predictions
  - [ ] Convert to DimABSA format
  - [ ] Create submission file
- [ ] Implement `validate_submission.py`
- [ ] Test on dev set
- [ ] Generate final submission

### Phase 5: Evaluation âœ…
- [ ] Run official evaluation script
- [ ] Compare with baseline
- [ ] Upload to CodaBench

---

## Answer to Your Question

**Q: If we convert DimABSA data to DESS format, how can we submit results?**

**A: We convert BACK from DESS predictions to DimABSA format!**

### The Two-Way Conversion:

1. **Training**: DimABSA â†’ DESS (forward)
2. **Submission**: DESS â†’ DimABSA (reverse)

### Why This Works:

- âœ… We keep original tokens in DESS format
- âœ… Token indices can be mapped back to text
- âœ… VA scores are preserved throughout
- âœ… No information is lost

### The Key Insight:

**DESS is just a processing format, not the final output.**

We use DESS for its powerful model architecture, but we always convert back to DimABSA format for submission. It's like using a different coordinate system for calculations, then converting back to the original system for the final answer.

---

## Next Steps

Ready to implement? The order should be:

1. **Data converter** (forward) - 1 day
2. **Model modifications** - 1 day  
3. **Training** - 1-2 days
4. **Inference converter** (reverse) - 1 day
5. **Submission & validation** - 0.5 day

**Total: ~5 days to first submission!**
