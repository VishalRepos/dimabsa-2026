{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DESS Model - Kaggle P100 GPU Setup\n",
    "## Aspect Sentiment Triplet Extraction with Cross-Attention Fusion\n",
    "\n",
    "This notebook runs the DESS (D2E2S) model with **Enhanced Semantic GCN + Cross-Attention Fusion**.\n",
    "\n",
    "**Latest Enhancement**: Cross-Attention Fusion (replaces TIN concatenation)\n",
    "\n",
    "**Previous Results**:\n",
    "- Enhanced SemGCN: 77.14% âœ…\n",
    "- + Contrastive: 76.10% âŒ (-1.04%)\n",
    "- + Boundary Refine: 71.46% âŒ (-5.68%)\n",
    "\n",
    "**Target**: 77.6-77.8% (+0.5-0.7%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Clone Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/VishalRepos/DESS-improved.git\n",
    "%cd DESS-improved/Codebase\n",
    "!echo \"\\n=== Latest Commits ===\"\n",
    "!git log --oneline -5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Check GPU Availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install compatible versions\n",
    "!pip install -q numpy==1.26.4\n",
    "!pip install -q transformers==4.36.0\n",
    "!pip install -q torch==2.1.0\n",
    "!pip install -q Jinja2==3.1.2\n",
    "!pip install -q tensorboardX==2.6\n",
    "!pip install -q tqdm==4.65.0\n",
    "!pip install -q scikit-learn==1.3.2\n",
    "!pip install -q 'spacy>=3.7.2,<3.8.0'\n",
    "!pip install -q matplotlib==3.8.0\n",
    "!pip install -q torch_geometric==2.4.0\n",
    "!pip install -q 'pydantic>=2.7.0'\n",
    "\n",
    "# Restart kernel to apply changes\n",
    "import os\n",
    "os.kill(os.getpid(), 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Import Libraries and Check Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import transformers\n",
    "import os\n",
    "\n",
    "print(\"=== Package Versions ===\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"Transformers version: {transformers.__version__}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"\\n=== GPU Information ===\")\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA Version: {torch.version.cuda}\")\n",
    "    print(f\"GPU Device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "print(f\"\\n=== Verification ===\")\n",
    "print(f\"NumPy has dtypes: {hasattr(np, 'dtypes')} \u2713\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Verify Data Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -la data/14res/\n",
    "!ls -la data/14lap/\n",
    "!ls -la data/15res/\n",
    "!ls -la data/16res/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Test Cross-Attention Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ..\n",
    "!python test_cross_attention.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6a. Test Triplet Extraction (Optional)\n",
    "### See how model extracts triplets in JSON format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to see triplet extraction in JSON format (1 epoch only)\n",
    "# %cd Codebase\n",
    "# !python train.py \\\n",
    "#     --seed 42 \\\n",
    "#     --max_span_size 8 \\\n",
    "#     --batch_size 16 \\\n",
    "#     --epochs 1 \\\n",
    "#     --dataset 14res \\\n",
    "#     --pretrained_deberta_name microsoft/deberta-v3-base \\\n",
    "#     --deberta_feature_dim 768 \\\n",
    "#     --hidden_dim 384 \\\n",
    "#     --emb_dim 768 \\\n",
    "#     --use_enhanced_semgcn \\\n",
    "#     --print_triplets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Full Training - Enhanced SemGCN + Cross-Attention Fusion (120 epochs)\n",
    "### Expected: Triplet F1 77.6-77.8%, Entity F1 88.7-89.0%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd Codebase\n",
    "!python train.py \\\n",
    "    --seed 42 \\\n",
    "    --max_span_size 8 \\\n",
    "    --batch_size 16 \\\n",
    "    --epochs 120 \\\n",
    "    --dataset 14res \\\n",
    "    --pretrained_deberta_name microsoft/deberta-v3-base \\\n",
    "    --deberta_feature_dim 768 \\\n",
    "    --hidden_dim 384 \\\n",
    "    --emb_dim 768 \\\n",
    "    --use_enhanced_semgcn \\\n",
    "    --use_cross_attention \\\n",
    "    --cross_attention_heads 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Baseline Comparison - Enhanced SemGCN Only\n",
    "### For comparison: Expected Triplet F1 77.14%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to run baseline (Enhanced SemGCN without cross-attention)\n",
    "# !python train.py \\\n",
    "#     --seed 42 \\\n",
    "#     --max_span_size 8 \\\n",
    "#     --batch_size 16 \\\n",
    "#     --epochs 120 \\\n",
    "#     --dataset 14res \\\n",
    "#     --pretrained_deberta_name microsoft/deberta-v3-base \\\n",
    "#     --deberta_feature_dim 768 \\\n",
    "#     --hidden_dim 384 \\\n",
    "#     --emb_dim 768 \\\n",
    "#     --use_enhanced_semgcn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Test on Other Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Test on Other Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10a. Laptop 2014 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to test on Laptop 2014 dataset\n",
    "# !python train.py \\\n",
    "#     --seed 42 \\\n",
    "#     --max_span_size 8 \\\n",
    "#     --batch_size 16 \\\n",
    "#     --epochs 120 \\\n",
    "#     --dataset 14lap \\\n",
    "#     --pretrained_deberta_name microsoft/deberta-v3-base \\\n",
    "#     --deberta_feature_dim 768 \\\n",
    "#     --hidden_dim 384 \\\n",
    "#     --emb_dim 768 \\\n",
    "#     --use_enhanced_semgcn \\\n",
    "#     --use_cross_attention \\\n",
    "#     --cross_attention_heads 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10b. Restaurant 2015 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to test on Restaurant 2015 dataset\n",
    "# !python train.py \\\n",
    "#     --seed 42 \\\n",
    "#     --max_span_size 8 \\\n",
    "#     --batch_size 16 \\\n",
    "#     --epochs 120 \\\n",
    "#     --dataset 15res \\\n",
    "#     --pretrained_deberta_name microsoft/deberta-v3-base \\\n",
    "#     --deberta_feature_dim 768 \\\n",
    "#     --hidden_dim 384 \\\n",
    "#     --emb_dim 768 \\\n",
    "#     --use_enhanced_semgcn \\\n",
    "#     --use_cross_attention \\\n",
    "#     --cross_attention_heads 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. View Training Logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -lh log/14res/\n",
    "!echo \"\\n=== Latest Training Log ===\"\n",
    "!tail -100 log/14res/train_*.log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Check Best Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import glob\n",
    "\n",
    "# Find latest results file\n",
    "result_files = glob.glob('log/14res/*.json')\n",
    "if result_files:\n",
    "    latest_file = max(result_files, key=lambda x: os.path.getmtime(x))\n",
    "    print(f\"Latest results: {latest_file}\\n\")\n",
    "    \n",
    "    with open(latest_file, 'r') as f:\n",
    "        results = json.load(f)\n",
    "    \n",
    "    print(\"=== Best Results ===\")\n",
    "    print(f\"Entity F1: {results.get('entity_f1', 'N/A')}\")\n",
    "    print(f\"Triplet F1: {results.get('triplet_f1', 'N/A')}\")\n",
    "    print(f\"Best Epoch: {results.get('best_epoch', 'N/A')}\")\n",
    "else:\n",
    "    print(\"No results found yet. Run training first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Performance Summary\n",
    "\n",
    "### Expected Results:\n",
    "\n",
    "| Configuration | Entity F1 | Triplet F1 | Change |\n",
    "|--------------|-----------|------------|--------|\n",
    "| Baseline (Original) | 87.65% | 75.75% | --- |\n",
    "| + Enhanced SemGCN | 88.68% | 77.14% | +1.39% |\n",
    "| + Contrastive | 88.19% | 76.10% | -1.04% âŒ |\n",
    "| + Boundary Refine | 85.53% | 71.46% | -5.68% âŒ |\n",
    "| **+ Cross-Attention** | **88.7-89.0%** | **77.6-77.8%** | **+0.5-0.7%** âœ… |\n",
    "\n",
    "### Latest Enhancement: Cross-Attention Fusion\n",
    "- ðŸŽ¯ **Problem**: TIN just concatenates semantic and syntactic features (50-50 split)\n",
    "- âœ… **Solution**: Multi-head cross-attention learns which features are important\n",
    "- ðŸ“ˆ **Expected Gain**: +0.5-0.7% Triplet F1\n",
    "\n",
    "### Key Features:\n",
    "- âœ… Enhanced Semantic GCN with relative position encoding\n",
    "- âœ… Global context aggregation\n",
    "- âœ… Multi-scale feature extraction\n",
    "- âœ… **Cross-Attention Fusion** (NEW)\n",
    "  - Semantic features query syntactic features\n",
    "  - Syntactic features query semantic features\n",
    "  - Multi-head attention (8 heads)\n",
    "  - Learned feature importance\n",
    "\n",
    "### Training Configuration:\n",
    "```bash\n",
    "python train.py --dataset 14res --epochs 120 \\\n",
    "    --pretrained_deberta_name microsoft/deberta-v3-base \\\n",
    "    --deberta_feature_dim 768 --hidden_dim 384 --emb_dim 768 \\\n",
    "    --use_enhanced_semgcn \\\n",
    "    --use_cross_attention \\\n",
    "    --cross_attention_heads 8\n",
    "```\n",
    "\n",
    "### Why Cross-Attention Works:\n",
    "1. **Dynamic Weighting**: Learns which features matter (not fixed 50-50)\n",
    "2. **Bidirectional**: Both semantic and syntactic query each other\n",
    "3. **Multi-Head**: Captures different feature relationships\n",
    "4. **Proven Approach**: Standard in transformers, well-understood\n",
    "5. **Lower Risk**: Replaces module, doesn't add complexity\n",
    "\n",
    "### Triplet Extraction Visualization:\n",
    "\n",
    "Use `--print_triplets` flag to see how sentences are classified:\n",
    "\n",
    "```bash\n",
    "python train.py --dataset 14res --epochs 1 \\\n",
    "    --use_enhanced_semgcn --print_triplets\n",
    "```\n",
    "\n",
    "**Output Format (JSON)**:\n",
    "```json\n",
    "{\"ID\": \"sentence_1_0\", \"Text\": \"the food was delicious\", \"Quadruplet\": [{\"Aspect\": \"food\", \"Opinion\": \"delicious\", \"Sentiment\": \"POS\"}]}\n",
    "```\n",
    "\n",
    "**Save to file**:\n",
    "```bash\n",
    "python train.py --print_triplets ... > output.txt 2>&1\n",
    "grep '^{' output.txt > triplets.jsonl\n",
    "```\n",
    "\n",
    "### Next Steps to Reach 80% F1:\n",
    "1. âœ… Cross-Attention Fusion (+0.5-0.7%) - **CURRENT**\n",
    "2. Data Augmentation (+0.3-0.5%)\n",
    "3. Ensemble Methods (+0.3-0.5%)\n",
    "4. Advanced span extraction (+0.2-0.4%)\n",
    "\n",
    "**Target**: 77.7% + 1.3-2.1% = **79.0-79.8%** (approaching 80%)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}