{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline-DeBERTa Training for DimABSA 2026\n",
    "\n",
    "**Subtask 2**: Dimensional Aspect Sentiment Triplet Extraction\n",
    "\n",
    "**Model**: Pipeline-based with DeBERTa-v3-base\n",
    "\n",
    "---\n",
    "\n",
    "## Setup Requirements\n",
    "- **GPU**: T4 or P100 (enable in Settings ‚Üí Accelerator)\n",
    "- **Time**: ~2-3 hours for both domains\n",
    "- **Internet**: Required for downloading code and data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Clone Repository and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the repository\n",
    "!git clone https://github.com/VishalRepos/dimabsa-2026.git\n",
    "%cd dimabsa-2026/Pipeline-DeBERTa\n",
    "\n",
    "# Install dependencies\n",
    "!pip install -q transformers torch sentencepiece protobuf\n",
    "\n",
    "print(\"‚úì Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Download Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data directory\n",
    "!mkdir -p data/track_a/subtask_2/eng\n",
    "\n",
    "# Download restaurant data\n",
    "!wget -q https://raw.githubusercontent.com/DimABSA/DimABSA2026/main/task-dataset/track_a/subtask_2/eng/eng_restaurant_train_alltasks.jsonl \\\n",
    "    -O data/track_a/subtask_2/eng/eng_restaurant_train_alltasks.jsonl\n",
    "!wget -q https://raw.githubusercontent.com/DimABSA/DimABSA2026/main/task-dataset/track_a/subtask_2/eng/eng_restaurant_dev_task2.jsonl \\\n",
    "    -O data/track_a/subtask_2/eng/eng_restaurant_dev_task2.jsonl\n",
    "\n",
    "# Download laptop data\n",
    "!wget -q https://raw.githubusercontent.com/DimABSA/DimABSA2026/main/task-dataset/track_a/subtask_2/eng/eng_laptop_train_alltasks.jsonl \\\n",
    "    -O data/track_a/subtask_2/eng/eng_laptop_train_alltasks.jsonl\n",
    "!wget -q https://raw.githubusercontent.com/DimABSA/DimABSA2026/main/task-dataset/track_a/subtask_2/eng/eng_laptop_dev_task2.jsonl \\\n",
    "    -O data/track_a/subtask_2/eng/eng_laptop_dev_task2.jsonl\n",
    "\n",
    "print(\"‚úì Dataset downloaded\")\n",
    "!ls -lh data/track_a/subtask_2/eng/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Verify GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è WARNING: GPU not available! Enable GPU in Settings ‚Üí Accelerator ‚Üí GPU T4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Train Restaurant Domain\n",
    "\n",
    "**Dataset**: 2,284 training samples\n",
    "\n",
    "**Time**: ~30-45 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python run_task2\\&3_trainer_multilingual.py \\\n",
    "  --task 2 \\\n",
    "  --domain res \\\n",
    "  --language eng \\\n",
    "  --data_path ./ \\\n",
    "  --train_data data/track_a/subtask_2/eng/eng_restaurant_train_alltasks.jsonl \\\n",
    "  --infer_data data/track_a/subtask_2/eng/eng_restaurant_dev_task2.jsonl \\\n",
    "  --bert_model_type microsoft/deberta-v3-base \\\n",
    "  --mode train \\\n",
    "  --epoch_num 3 \\\n",
    "  --batch_size 8 \\\n",
    "  --learning_rate 1e-3 \\\n",
    "  --tuning_bert_rate 1e-5 \\\n",
    "  --inference_beta 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Check Restaurant Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load predictions\n",
    "with open(\"tasks/subtask_2/pred_eng_restaurant.jsonl\", 'r') as f:\n",
    "    predictions = [json.loads(line) for line in f]\n",
    "\n",
    "# Calculate statistics\n",
    "total_triplets = sum(len(p['Triplet']) for p in predictions)\n",
    "\n",
    "print(f\"üìä Restaurant Results:\")\n",
    "print(f\"  Total predictions: {len(predictions)}\")\n",
    "print(f\"  Total triplets: {total_triplets}\")\n",
    "print(f\"  Avg triplets/sample: {total_triplets/len(predictions):.2f}\")\n",
    "\n",
    "print(f\"\\nüìù First 3 predictions:\")\n",
    "for i, pred in enumerate(predictions[:3]):\n",
    "    print(f\"\\n{i+1}. ID: {pred['ID']}\")\n",
    "    print(f\"   Triplets: {len(pred['Triplet'])}\")\n",
    "    if pred['Triplet']:\n",
    "        for t in pred['Triplet'][:2]:  # Show first 2 triplets\n",
    "            print(f\"   - Aspect: {t['Aspect']}, Opinion: {t['Opinion']}, VA: {t['VA']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Train Laptop Domain\n",
    "\n",
    "**Dataset**: 4,076 training samples\n",
    "\n",
    "**Time**: ~60-90 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python run_task2\\&3_trainer_multilingual.py \\\n",
    "  --task 2 \\\n",
    "  --domain lap \\\n",
    "  --language eng \\\n",
    "  --data_path ./ \\\n",
    "  --train_data data/track_a/subtask_2/eng/eng_laptop_train_alltasks.jsonl \\\n",
    "  --infer_data data/track_a/subtask_2/eng/eng_laptop_dev_task2.jsonl \\\n",
    "  --bert_model_type microsoft/deberta-v3-base \\\n",
    "  --mode train \\\n",
    "  --epoch_num 3 \\\n",
    "  --batch_size 8 \\\n",
    "  --learning_rate 1e-3 \\\n",
    "  --tuning_bert_rate 1e-5 \\\n",
    "  --inference_beta 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Check Laptop Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load predictions\n",
    "with open(\"tasks/subtask_2/pred_eng_laptop.jsonl\", 'r') as f:\n",
    "    predictions = [json.loads(line) for line in f]\n",
    "\n",
    "# Calculate statistics\n",
    "total_triplets = sum(len(p['Triplet']) for p in predictions)\n",
    "\n",
    "print(f\"üíª Laptop Results:\")\n",
    "print(f\"  Total predictions: {len(predictions)}\")\n",
    "print(f\"  Total triplets: {total_triplets}\")\n",
    "print(f\"  Avg triplets/sample: {total_triplets/len(predictions):.2f}\")\n",
    "\n",
    "print(f\"\\nüìù First 3 predictions:\")\n",
    "for i, pred in enumerate(predictions[:3]):\n",
    "    print(f\"\\n{i+1}. ID: {pred['ID']}\")\n",
    "    print(f\"   Triplets: {len(pred['Triplet'])}\")\n",
    "    if pred['Triplet']:\n",
    "        for t in pred['Triplet'][:2]:  # Show first 2 triplets\n",
    "            print(f\"   - Aspect: {t['Aspect']}, Opinion: {t['Opinion']}, VA: {t['VA']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Validate Output Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_predictions(pred_file, domain_name):\n",
    "    \"\"\"Validate prediction format\"\"\"\n",
    "    with open(pred_file, 'r') as f:\n",
    "        predictions = [json.loads(line) for line in f]\n",
    "    \n",
    "    errors = []\n",
    "    for i, pred in enumerate(predictions):\n",
    "        # Check required keys\n",
    "        if 'ID' not in pred or 'Triplet' not in pred:\n",
    "            errors.append(f\"Line {i}: Missing required keys\")\n",
    "            continue\n",
    "        \n",
    "        # Check triplet format\n",
    "        for j, triplet in enumerate(pred['Triplet']):\n",
    "            if 'Aspect' not in triplet or 'Opinion' not in triplet or 'VA' not in triplet:\n",
    "                errors.append(f\"Line {i}, Triplet {j}: Missing keys\")\n",
    "                continue\n",
    "            \n",
    "            # Validate VA format\n",
    "            va = triplet['VA']\n",
    "            if '#' not in va:\n",
    "                errors.append(f\"Line {i}, Triplet {j}: VA missing '#'\")\n",
    "            else:\n",
    "                try:\n",
    "                    v, a = map(float, va.split('#'))\n",
    "                    if not (1.0 <= v <= 9.0) or not (1.0 <= a <= 9.0):\n",
    "                        errors.append(f\"Line {i}, Triplet {j}: VA out of range [1,9]\")\n",
    "                except:\n",
    "                    errors.append(f\"Line {i}, Triplet {j}: Invalid VA format\")\n",
    "    \n",
    "    if errors:\n",
    "        print(f\"‚ùå {domain_name}: Found {len(errors)} errors\")\n",
    "        for err in errors[:5]:\n",
    "            print(f\"  - {err}\")\n",
    "        return False\n",
    "    else:\n",
    "        print(f\"‚úÖ {domain_name}: All {len(predictions)} predictions valid!\")\n",
    "        return True\n",
    "\n",
    "# Validate both domains\n",
    "validate_predictions(\"tasks/subtask_2/pred_eng_restaurant.jsonl\", \"Restaurant\")\n",
    "validate_predictions(\"tasks/subtask_2/pred_eng_laptop.jsonl\", \"Laptop\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Package Results for Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create results directory\n",
    "!mkdir -p results\n",
    "\n",
    "# Copy all outputs\n",
    "!cp model/*.pth results/ 2>/dev/null || echo \"No models found\"\n",
    "!cp tasks/subtask_2/*.jsonl results/\n",
    "!cp log/*.log results/ 2>/dev/null || echo \"No logs found\"\n",
    "\n",
    "# Create zip file\n",
    "!zip -r pipeline_deberta_results.zip results/\n",
    "\n",
    "print(\"\\n‚úÖ Results packaged!\")\n",
    "print(\"\\nüì¶ Download: pipeline_deberta_results.zip\")\n",
    "print(\"\\nContents:\")\n",
    "!ls -lh results/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Training Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"TRAINING SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Restaurant stats\n",
    "with open(\"tasks/subtask_2/pred_eng_restaurant.jsonl\", 'r') as f:\n",
    "    res_preds = [json.loads(line) for line in f]\n",
    "    res_triplets = sum(len(p['Triplet']) for p in res_preds)\n",
    "\n",
    "print(f\"\\nüìä Restaurant Domain:\")\n",
    "print(f\"  Predictions: {len(res_preds)}\")\n",
    "print(f\"  Total triplets: {res_triplets}\")\n",
    "print(f\"  Avg triplets/sample: {res_triplets/len(res_preds):.2f}\")\n",
    "print(f\"  Model: model/task2_res_eng.pth\")\n",
    "print(f\"  Output: tasks/subtask_2/pred_eng_restaurant.jsonl\")\n",
    "\n",
    "# Laptop stats\n",
    "with open(\"tasks/subtask_2/pred_eng_laptop.jsonl\", 'r') as f:\n",
    "    lap_preds = [json.loads(line) for line in f]\n",
    "    lap_triplets = sum(len(p['Triplet']) for p in lap_preds)\n",
    "\n",
    "print(f\"\\nüíª Laptop Domain:\")\n",
    "print(f\"  Predictions: {len(lap_preds)}\")\n",
    "print(f\"  Total triplets: {lap_triplets}\")\n",
    "print(f\"  Avg triplets/sample: {lap_triplets/len(lap_preds):.2f}\")\n",
    "print(f\"  Model: model/task2_lap_eng.pth\")\n",
    "print(f\"  Output: tasks/subtask_2/pred_eng_laptop.jsonl\")\n",
    "\n",
    "print(f\"\\n‚úÖ Training Complete!\")\n",
    "print(f\"\\nüì• Download: pipeline_deberta_results.zip (from Output tab)\")\n",
    "print(\"=\" * 70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
